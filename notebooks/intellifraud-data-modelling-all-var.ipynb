{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-10-26T19:26:23.586449Z","iopub.status.busy":"2023-10-26T19:26:23.585977Z","iopub.status.idle":"2023-10-26T19:26:23.609870Z","shell.execute_reply":"2023-10-26T19:26:23.608564Z","shell.execute_reply.started":"2023-10-26T19:26:23.586412Z"},"trusted":true},"outputs":[],"source":["import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-26T21:19:28.675829Z","iopub.status.busy":"2023-10-26T21:19:28.675413Z","iopub.status.idle":"2023-10-26T21:19:28.693505Z","shell.execute_reply":"2023-10-26T21:19:28.692148Z","shell.execute_reply.started":"2023-10-26T21:19:28.675796Z"},"trusted":true},"outputs":[],"source":["# Viz Imports\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import plotly.express as px\n","# Increase the maximum number of columns displayed in Pandas to 200\n","pd.set_option('display.max_columns', 200)\n","pd.set_option('display.precision', 2)\n","# pd.options.display.float_format = '{:.0f}'.format\n","# Set the default style of Matplotlib plots to \"ggplot\"\n","plt.style.use('ggplot')\n","# Define custom color palette\n","my_palette = sns.color_palette(\"husl\", 2)\n","sns.set_style(\"whitegrid\")\n","\n","# All imports here\n","from sklearn.compose import make_column_selector\n","\n","from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n","from sklearn.metrics import accuracy_score # Library for model evaluation\n","from sklearn.model_selection import train_test_split # Library to split datset into test and train\n","\n","from sklearn.dummy import DummyClassifier\n","from sklearn.linear_model  import LogisticRegression # Logistic Regression Classifier\n","from sklearn.linear_model import SGDClassifier # Stochastic Gradient Descent Classifier\n","from sklearn.tree import DecisionTreeClassifier # Decision Tree Classifier\n","from sklearn.ensemble  import RandomForestClassifier # Random Forest Classifier\n","from sklearn.neighbors import KNeighborsClassifier # K Nearest neighbors Classifier\n","from sklearn.naive_bayes import GaussianNB #Naive Bayes Classifier\n","from sklearn.svm import SVC #Support vector Machine Classifier\n","from sklearn.ensemble import AdaBoostClassifier # Ada Boost Classifier\n","from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix, roc_auc_score\n","from sklearn.model_selection import cross_val_score, RepeatedStratifiedKFold\n","from sklearn.metrics import precision_recall_curve\n","from sklearn.metrics import average_precision_score\n","from sklearn.model_selection import cross_val_score, GridSearchCV, KFold, RandomizedSearchCV, train_test_split\n","from sklearn.metrics import average_precision_score, precision_recall_curve\n","from sklearn.model_selection import GridSearchCV\n","from sklearn import metrics\n","from sklearn.ensemble import StackingClassifier, VotingClassifier\n","\n","from xgboost import XGBClassifier\n","from lightgbm import LGBMClassifier\n","import joblib"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["file_list = ['Base.csv', 'variant_1.csv', 'variant_2.csv', 'variant_3.csv', 'variant_4.csv', 'variant_5.csv']"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-26T19:26:24.512028Z","iopub.status.busy":"2023-10-26T19:26:24.511642Z","iopub.status.idle":"2023-10-26T19:26:31.326545Z","shell.execute_reply":"2023-10-26T19:26:31.325309Z","shell.execute_reply.started":"2023-10-26T19:26:24.511996Z"},"trusted":true},"outputs":[],"source":["intellifraud_dataset = pd.DataFrame()\n","\n","for file in file_list:\n","    input_df = pd.read_csv(f\"../data/{file}\")\n","    print('File Name : ', file)\n","    print(f'Rows - {input_df.shape[0]}, Columns - {input_df.shape[1]}')\n","    print(input_df['fraud_bool'].value_counts())\n","\n","    # Append the data into fraud dataset\n","    intellifraud_dataset = intellifraud_dataset.append(input_df)\n","\n","print('Shape of intellifraud_dataset : ', intellifraud_dataset.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# input_df = pd.read_csv(f\"../data/Base.csv\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-26T19:26:31.329322Z","iopub.status.busy":"2023-10-26T19:26:31.328969Z","iopub.status.idle":"2023-10-26T19:26:31.896659Z","shell.execute_reply":"2023-10-26T19:26:31.895493Z","shell.execute_reply.started":"2023-10-26T19:26:31.329292Z"},"trusted":true},"outputs":[],"source":["# Checking the datatype of the columns\n","intellifraud_dataset.info()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-26T19:26:31.898506Z","iopub.status.busy":"2023-10-26T19:26:31.898051Z","iopub.status.idle":"2023-10-26T19:26:32.042725Z","shell.execute_reply":"2023-10-26T19:26:32.041397Z","shell.execute_reply.started":"2023-10-26T19:26:31.898464Z"},"trusted":true},"outputs":[],"source":["# Extract Continuous & Categorical Columns\n","cat_cols = intellifraud_dataset.select_dtypes(include=['object']).columns.tolist()\n","cont_cols = intellifraud_dataset.select_dtypes(exclude=['object']).columns.tolist()\n","print(f'Categorical Columns - {cat_cols}')\n","print(\"=========================================\")\n","print(f'Continuous Columns - {cont_cols}')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-26T19:26:32.045953Z","iopub.status.busy":"2023-10-26T19:26:32.045499Z","iopub.status.idle":"2023-10-26T19:26:33.555221Z","shell.execute_reply":"2023-10-26T19:26:33.553900Z","shell.execute_reply.started":"2023-10-26T19:26:32.045895Z"},"trusted":true},"outputs":[],"source":["# Get Information on Categorical/Object Variables\n","intellifraud_dataset.describe(include=[\"object\", \"bool\"]).transpose()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-26T19:26:33.557237Z","iopub.status.busy":"2023-10-26T19:26:33.556801Z","iopub.status.idle":"2023-10-26T19:26:33.987826Z","shell.execute_reply":"2023-10-26T19:26:33.986484Z","shell.execute_reply.started":"2023-10-26T19:26:33.557203Z"},"trusted":true},"outputs":[],"source":["# Printing the unique values of Categorcal columns\n","for cols in cat_cols:\n","    print(cols, '-', intellifraud_dataset[cols].unique())"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-26T19:26:33.990210Z","iopub.status.busy":"2023-10-26T19:26:33.989739Z","iopub.status.idle":"2023-10-26T19:26:34.985848Z","shell.execute_reply":"2023-10-26T19:26:34.984462Z","shell.execute_reply.started":"2023-10-26T19:26:33.990167Z"},"trusted":true},"outputs":[],"source":["# Details of Numeric Columns\n","intellifraud_dataset.describe().T"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-26T19:26:34.987943Z","iopub.status.busy":"2023-10-26T19:26:34.987604Z","iopub.status.idle":"2023-10-26T19:26:36.054969Z","shell.execute_reply":"2023-10-26T19:26:36.053480Z","shell.execute_reply.started":"2023-10-26T19:26:34.987914Z"},"trusted":true},"outputs":[],"source":["# Printing the unique count of Cont columns\n","# Get the number of unique values in each column of the DataFrame\n","intellifraud_dataset.nunique()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-26T19:26:36.057084Z","iopub.status.busy":"2023-10-26T19:26:36.056700Z","iopub.status.idle":"2023-10-26T19:26:37.719742Z","shell.execute_reply":"2023-10-26T19:26:37.718529Z","shell.execute_reply.started":"2023-10-26T19:26:36.057050Z"},"trusted":true},"outputs":[],"source":["# Printing the unique values of Categorcal columns\n","discreet_column = []\n","for cols in cont_cols:\n","    if len(list(intellifraud_dataset[cols].unique())) < 15:\n","        discreet_column.append(cols)\n","        print(cols, '-', intellifraud_dataset[cols].unique())\n","discreet_column"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-26T19:26:37.722995Z","iopub.status.busy":"2023-10-26T19:26:37.721661Z","iopub.status.idle":"2023-10-26T19:26:38.197632Z","shell.execute_reply":"2023-10-26T19:26:38.196008Z","shell.execute_reply.started":"2023-10-26T19:26:37.722949Z"},"trusted":true},"outputs":[],"source":["# EDA to explore Fraud vs Non Fraud\n","fraud_count = intellifraud_dataset[\"fraud_bool\"].map({1:'Fraud', 0:'Not Fraud'}).to_frame()\n","ax = sns.countplot(\n","                    x=fraud_count['fraud_bool'],\n","                    order=fraud_count['fraud_bool'].value_counts(ascending=True).index\n","                )\n","        \n","abs_values = fraud_count['fraud_bool'].value_counts(ascending=True)\n","rel_values = fraud_count['fraud_bool'].value_counts(ascending=True, normalize=True).values * 100\n","lbls = [f'{p[0]:,.0f} ({p[1]:.0f}%)' for p in zip(abs_values, rel_values)]\n","\n","ax.bar_label(container=ax.containers[0], labels=lbls)\n","ax.set(title ='Fraud vs Non Fraud Count (All Variants)')\n","ax.grid(False)\n","sns.despine(left=True)\n","ax.set(xlabel=None)\n","ax.set(ylabel=None)\n","ax.set_yticklabels([])"]},{"cell_type":"markdown","metadata":{},"source":["## Convert All Columns to Numeric"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-26T19:29:15.582016Z","iopub.status.busy":"2023-10-26T19:29:15.581665Z","iopub.status.idle":"2023-10-26T19:29:15.592598Z","shell.execute_reply":"2023-10-26T19:29:15.591468Z","shell.execute_reply.started":"2023-10-26T19:29:15.581984Z"},"trusted":true},"outputs":[],"source":["def map_categorical_column(df):\n","    \n","    ''' Function to map the categorical columns '''\n","     \n","    map_payment_type      = {'AA':0, 'AB':1, 'AC':2, 'AD':3, 'AE':4}\n","    map_employment_status = {'CA':0, 'CB':1, 'CC':2, 'CD':3, 'CE':4,'CF':5,'CG':6}\n","    map_housing_status    = {'BA':0, 'BB':1, 'BC':2, 'BD':3, 'BE':4,'BF':5,'BG':6}\n","    map_source            = {'INTERNET':0,'TELEAPP':1}\n","    map_device_os         = {'windows':0,'other':1,'linux':2,'macintosh':3,'x11':4}\n","    \n","    # Updating the mapping in dataframe\n","    df[\"payment_type\"]                 = df[\"payment_type\"].map(map_payment_type)\n","    df[\"employment_status\"]            = df[\"employment_status\"].map(map_employment_status)\n","    df[\"housing_status\"]               = df[\"housing_status\"].map(map_housing_status)\n","    df[\"source\"]                       = df[\"source\"].map(map_source)\n","    df[\"device_os\"]                    = df[\"device_os\"].map(map_device_os)\n","\n","    return df"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-26T19:29:15.594472Z","iopub.status.busy":"2023-10-26T19:29:15.594030Z","iopub.status.idle":"2023-10-26T19:29:16.321441Z","shell.execute_reply":"2023-10-26T19:29:16.319987Z","shell.execute_reply.started":"2023-10-26T19:29:15.594442Z"},"trusted":true},"outputs":[],"source":["# input_df_copy = input_df.copy()\n","intellifraud_dataset_num = map_categorical_column(intellifraud_dataset)\n","intellifraud_dataset_num.head()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["intellifraud_dataset_num.fraud_bool.value_counts()"]},{"cell_type":"markdown","metadata":{},"source":["## Features Selection"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-26T19:29:16.323217Z","iopub.status.busy":"2023-10-26T19:29:16.322879Z","iopub.status.idle":"2023-10-26T19:29:16.330055Z","shell.execute_reply":"2023-10-26T19:29:16.328587Z","shell.execute_reply.started":"2023-10-26T19:29:16.323188Z"},"trusted":true},"outputs":[],"source":["# Import the necessary libraries for feature selection\n","from sklearn.feature_selection import VarianceThreshold, SelectKBest, SelectFromModel, chi2, mutual_info_classif\n","from sklearn.linear_model import Lasso, Ridge\n","from sklearn.ensemble import ExtraTreesClassifier\n","from imblearn.under_sampling import NearMiss\n","from collections import Counter"]},{"cell_type":"markdown","metadata":{},"source":["##### Variance Threshold Test - Removes all low-variance features."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-26T19:29:16.332084Z","iopub.status.busy":"2023-10-26T19:29:16.331768Z","iopub.status.idle":"2023-10-26T19:29:16.924814Z","shell.execute_reply":"2023-10-26T19:29:16.923423Z","shell.execute_reply.started":"2023-10-26T19:29:16.332056Z"},"trusted":true},"outputs":[],"source":["# True: High Variance ; #False: Low Variance\n","selector = VarianceThreshold()\n","selector.fit(intellifraud_dataset_num)\n","low_variance_col = [column for column in intellifraud_dataset_num.columns if column not in intellifraud_dataset_num.columns[selector.get_support()]]\n","low_variance_col\n"]},{"cell_type":"markdown","metadata":{},"source":["##### Pearson's Correlation Matrix - Remove highly correlated features"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-26T19:29:16.926957Z","iopub.status.busy":"2023-10-26T19:29:16.926526Z","iopub.status.idle":"2023-10-26T19:29:21.377529Z","shell.execute_reply":"2023-10-26T19:29:21.375936Z","shell.execute_reply.started":"2023-10-26T19:29:16.926921Z"},"trusted":true},"outputs":[],"source":["# Multicollinearity Test\n","corr = intellifraud_dataset_num.drop(columns=['device_fraud_count', 'fraud_bool']).corr()\n","\n","# Generate a mask for the upper triangle\n","mask = np.triu(np.ones_like(corr, dtype=bool))\n","\n","# Plot correlation matrix with annotated values\n","fig, ax = plt.subplots(figsize=(11, 9))\n","\n","# Generate a custom diverging colormap\n","cmap = sns.diverging_palette(230, 20, as_cmap=True)\n","\n","# Draw the heatmap with the mask and correct aspect ratio\n","sns.heatmap(\n","            corr[(corr >= 0.3) | (corr <= -0.3)], \n","            mask=mask,\n","            cmap='coolwarm', \n","            vmax=.3, \n","            center=0,\n","            square=True, \n","            linewidths=.5, \n","            cbar_kws={\"shrink\": .5},\n","            annot=True, \n","            annot_kws={\"fontsize\": 8},\n","            fmt=\".2f\", \n",")\n","\n","plt.title('Correlation Heatmap')\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["velocity_4w can re removed. It shows strong co-linearity with Month"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# ##### Recursive Feature Elimination\n","\n","# Fraud Transactions\n","intellifraud_df_fraud = intellifraud_dataset_num[intellifraud_dataset_num.fraud_bool == 1]\n","display(f'Shape of train_df_fraud {intellifraud_df_fraud.shape}')\n","\n","# Non Fraud Transactions\n","intellifraud_df_non_fraud = intellifraud_dataset_num[intellifraud_dataset_num.fraud_bool == 0].sample(intellifraud_df_fraud.shape[0])\n","display(f'Shape of train_df_non_fraud {intellifraud_df_non_fraud.shape}')\n","\n","# Merge Fraud & Non Fraud\n","train_df_merged = pd.concat([intellifraud_df_fraud, intellifraud_df_non_fraud])\n","display(f'Shape of train_df_merged {train_df_merged.shape}')\n","\n","# Fit Model\n","X                 = train_df_merged.drop(columns=['fraud_bool', 'device_fraud_count', 'velocity_4w', 'x1', 'x2'])\n","y                 = train_df_merged['fraud_bool']\n","\n","clf = RandomForestClassifier(random_state=42, max_depth=10).fit(X, y)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["feature_importances = pd.DataFrame(clf.feature_importances_,\n","                                    index = X.columns,\n","                                    columns=['Feature_Importance']).sort_values('Feature_Importance', ascending=False\n","                                            )\n","# display(feature_importances)\n","# display('Feature Importance:', feature_importances['Feature_Importance'])\n","ax = feature_importances.head(11).plot(kind=\"bar\")\n","ax.set(title ='Top 10 Features')\n","ax.grid(False)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["feature_importances.head(11)"]},{"cell_type":"markdown","metadata":{},"source":["### Define Initial Models for Effective Attributes"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Function for Precsion, Recall and F1 Score\n","def calc_classfier_metric(classifier, y_test, y_pred):\n","    '''\n","    Function for Precsion, Recall and F1 Score\n","    '''\n","    accuracy      = accuracy_score(y_test, y_pred)\n","    precision     = precision_score(y_test, y_pred)\n","    recall        = recall_score(y_test, y_pred)\n","    F1_score      = f1_score(y_test, y_pred)\n","    roc_auc_scr   = roc_auc_score(y_test, y_pred)\n","    conf_mat      = confusion_matrix(y_test, y_pred)\n","    fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred)\n","    \n","    return accuracy, precision, recall, F1_score, roc_auc_scr, conf_mat, fpr, tpr"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-26T20:58:14.326601Z","iopub.status.busy":"2023-10-26T20:58:14.326162Z","iopub.status.idle":"2023-10-26T20:58:14.338212Z","shell.execute_reply":"2023-10-26T20:58:14.337311Z","shell.execute_reply.started":"2023-10-26T20:58:14.326565Z"},"trusted":true},"outputs":[],"source":["# Build Classification Model\n","def build_individual_classifier_model(X_train, X_test, y_train, y_test, classifier_model, under_sample_size):\n","    '''\n","    Function to Build Classification Model for Individual Classifier\n","    '''\n","    print('Into build_individual_classifier_model')\n","    \n","    classifier_performance = []\n","    cnf_lst = []\n","\n","    for classifier in classifier_model:\n","\n","        # Fitting the training set into classification model\n","        classifier.fit(X_train,y_train)\n","\n","        # Predicting the output on test datset\n","        y_pred = classifier.predict(X_test)    \n","\n","        # Cross Validation Score on training test\n","        cv = RepeatedStratifiedKFold(n_splits=5, random_state=42)\n","        scores = cross_val_score(classifier, X_train,y_train, cv=5, scoring='f1_weighted')\n","        cv_score_mean = scores.mean()\n","\n","        # Classification score\n","        accuracy, precision, recall, F1_score, roc_auc_scr, conf_mat, fpr, tpr = calc_classfier_metric(classifier, y_test, y_pred)\n","        classifier_performance.append([classifier.__class__.__name__, conf_mat, accuracy, precision, recall, F1_score, roc_auc_scr, cv_score_mean, fpr, tpr])\n","        \n","        # Store the model into pkl\n","        joblib.dump(classifier, f'../model/sample_1_{under_sample_size}/{classifier.__class__.__name__}.pkl')\n","     \n","    class_perf_df = pd.DataFrame(classifier_performance, columns=['Classifier', 'Conf_Mtrx', 'Accuracy', 'Precision', 'Recall', 'F1_Score', 'ROC_AUC_Scr', 'CV_Score', 'FPR', 'TPR']).sort_values('F1_Score', ascending = False)\n","    \n","    return class_perf_df"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-26T20:58:14.550741Z","iopub.status.busy":"2023-10-26T20:58:14.550027Z","iopub.status.idle":"2023-10-26T20:58:14.561675Z","shell.execute_reply":"2023-10-26T20:58:14.560760Z","shell.execute_reply.started":"2023-10-26T20:58:14.550706Z"},"trusted":true},"outputs":[],"source":["def build_voting_classifier_model(X_train, X_test, y_train, y_test, classifier_model, ind_class_model_df, under_sample_size):\n","    \n","    '''\n","    Function to Classifier Model for Voting Classifier\n","    '''\n","    \n","    print('Into build_voting_classifier_model')\n","    \n","    classifier_performance = []\n","    cnf_lst = []\n","\n","    # Voting Classifier                \n","    clf1 = classifier_model[0]\n","    clf2 = classifier_model[1]\n","    clf3 = classifier_model[2]\n","    \n","    vote_classifier = VotingClassifier(\n","                                        estimators=[('ada', clf1),('xgb', clf2), ('lgb', clf3)],\n","                                        voting='soft'\n","                                    )\n","    \n","    # Fitting the training set into classification model\n","    vote_classifier.fit(X_train,y_train)\n","\n","    # Predicting the output on test datset\n","    y_pred = vote_classifier.predict(X_test)    \n","\n","    # Cross Validation Score on training test\n","    cv = RepeatedStratifiedKFold(n_splits=5, random_state=42)\n","    scores = cross_val_score(vote_classifier, X_train,y_train, cv=5, scoring='f1_weighted')\n","    cv_score_mean = scores.mean()\n","\n","    # Classification score\n","    accuracy, precision, recall, F1_score, roc_auc_scr, conf_mat, fpr, tpr = calc_classfier_metric(vote_classifier, y_test, y_pred)\n","    classifier_performance.append([vote_classifier.__class__.__name__, conf_mat, accuracy, precision, recall, F1_score, roc_auc_scr, cv_score_mean, fpr, tpr])\n","    \n","    # Store the model into pkl\n","    joblib.dump(vote_classifier, f'../model/sample_1_{under_sample_size}/{vote_classifier.__class__.__name__}.pkl')\n","        \n","    class_perf_df = pd.DataFrame(classifier_performance, columns=['Classifier', 'Conf_Mtrx', 'Accuracy', 'Precision', 'Recall', 'F1_Score', 'ROC_AUC_Scr', 'CV_Score', 'FPR', 'TPR']).sort_values('F1_Score', ascending = False)\n","    \n","    voting_class_df = pd.concat([ind_class_model_df, class_perf_df])\n","    \n","    return voting_class_df"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-26T21:23:17.581494Z","iopub.status.busy":"2023-10-26T21:23:17.581098Z","iopub.status.idle":"2023-10-26T21:23:17.594646Z","shell.execute_reply":"2023-10-26T21:23:17.593100Z","shell.execute_reply.started":"2023-10-26T21:23:17.581463Z"},"trusted":true},"outputs":[],"source":["# Build Classification Model\n","def build_stacking_classifier_model(X_train, X_test, y_train, y_test, classifier_model, prev_class_model_df, under_sample_size):\n","    \n","    '''\n","    Function to Classifier Model for Voting Classifier\n","    '''\n","    \n","    print('Into build_stacking_classifier_model')\n","    \n","    classifier_performance = []\n","    cnf_lst = []\n","\n","    # Voting Classifier                \n","    clf1 = classifier_model[0]\n","    clf2 = classifier_model[1]\n","    clf3 = classifier_model[2]\n","    \n","    stacking_classifier = StackingClassifier(\n","                                                estimators = [('ada', clf1),('xgb', clf2), ('lgb', clf3)],\n","                                                final_estimator = LogisticRegression(),\n","                                                cv = 5\n","                                    )\n","    \n","    \n","    # Fitting the training set into classification model\n","    stacking_classifier.fit(X_train,y_train)\n","\n","    # Predicting the output on test datset\n","    y_pred = stacking_classifier.predict(X_test)    \n","\n","    # Cross Validation Score on training test\n","    cv = RepeatedStratifiedKFold(n_splits=5, random_state=42)\n","    scores = cross_val_score(stacking_classifier, X_train,y_train, cv=5, scoring='f1_weighted')\n","    cv_score_mean = scores.mean()\n","\n","    # Classification score\n","    accuracy, precision, recall, F1_score, roc_auc_scr, conf_mat, fpr, tpr = calc_classfier_metric(stacking_classifier, y_test, y_pred)\n","    classifier_performance.append([stacking_classifier.__class__.__name__, conf_mat, accuracy, precision, recall, F1_score, roc_auc_scr, cv_score_mean, fpr, tpr])\n","    \n","    # Store the model into pkl\n","    joblib.dump(stacking_classifier, f'../model/sample_1_{under_sample_size}/{stacking_classifier.__class__.__name__}.pkl')        \n","    class_perf_df = pd.DataFrame(classifier_performance, columns=['Classifier', 'Conf_Mtrx', 'Accuracy', 'Precision', 'Recall', 'F1_Score', 'ROC_AUC_Scr', 'CV_Score', 'FPR', 'TPR']).sort_values('F1_Score', ascending = False)\n","    \n","    stacking_class_df = pd.concat([prev_class_model_df, class_perf_df])\n","    \n","    return stacking_class_df"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-26T21:23:23.165022Z","iopub.status.busy":"2023-10-26T21:23:23.164576Z","iopub.status.idle":"2023-10-26T21:23:23.175092Z","shell.execute_reply":"2023-10-26T21:23:23.174174Z","shell.execute_reply.started":"2023-10-26T21:23:23.164986Z"},"trusted":true},"outputs":[],"source":["# Function for Confusion Matrix\n","def view_confusion_matrix(class_perf_df, columns):\n","    '''\n","    Function for Confusion Matrix\n","    '''\n","    rows = int(class_perf_df.shape[0]/ columns)\n","    plt.figure(figsize=(15,13))\n","\n","    for i in range(class_perf_df.shape[0]):\n","        plt.subplot(rows,columns,i+1)\n","        plt.title(class_perf_df['Classifier'].loc[i])\n","        ax=sns.heatmap(class_perf_df['Conf_Mtrx'].loc[i],\n","                    annot=True,\n","                    cmap=\"coolwarm\",\n","                    fmt=\"d\",\n","                    cbar=False, \n","                    annot_kws={\"size\": 12},\n","                    linewidths=1.2,\n","                    linecolor='w',\n","                   )\n","        ax.set_xticklabels(ax.get_xticklabels(), rotation = 0, fontsize = 10)\n","        ax.set_yticklabels(ax.get_yticklabels(), rotation = 25, fontsize = 10)\n","        ax.set_xlabel('True label') \n","        ax.set_ylabel('Predicted label')\n","    \n","    return"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-26T21:23:26.715749Z","iopub.status.busy":"2023-10-26T21:23:26.715282Z","iopub.status.idle":"2023-10-26T21:23:26.729537Z","shell.execute_reply":"2023-10-26T21:23:26.728036Z","shell.execute_reply.started":"2023-10-26T21:23:26.715712Z"},"trusted":true},"outputs":[],"source":["def create_sample_set(train_df, non_fraud_sample_sizse):\n","    \n","    # Select columns\n","    train_df = train_df[['housing_status',\n","                            'device_os',\n","                            'credit_risk_score',\n","                            'current_address_months_count',\n","                            'has_other_cards',\n","                            'keep_alive_session',\n","                            'prev_address_months_count',\n","                            'phone_home_valid',\n","                            'proposed_credit_limit',\n","                            'name_email_similarity',\n","                            'income',\n","                            'fraud_bool' \n","                        ]]\n","                        \n","    # Fraud Transactions\n","    train_df_fraud = train_df[train_df.fraud_bool == 1]\n","    # display(f'Shape of train_df_fraud {train_df_fraud.shape}')\n","    \n","    # Non Fraud Transactions\n","    train_df_non_fraud = train_df[train_df.fraud_bool == 0].sample(train_df_fraud.shape[0] * non_fraud_sample_sizse)\n","    # display(f'Shape of train_df_non_fraud {train_df_non_fraud.shape}')\n","    \n","    # Merge Fraud & Non Fraud\n","    train_df_merged = pd.concat([train_df_fraud, train_df_non_fraud])\n"," \n","    # X & Y\n","    X                 = train_df_merged.drop(columns=['fraud_bool'])\n","    y                 = train_df_merged['fraud_bool']\n","\n","    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n","\n","    return X_train, y_train, X_test, y_test"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.metrics import PrecisionRecallDisplay, RocCurveDisplay\n","\n","def create_performance_graphs(X_test, y_test, sample_size):\n","\n","    # Sample Ratio 1:1\n","    classifier_list = ['AdaBoostClassifier.pkl', 'LGBMClassifier.pkl', 'XGBClassifier.pkl', 'StackingClassifier.pkl', 'VotingClassifier.pkl']\n","\n","    fig, [ax_roc, ax_prc] = plt.subplots(1, 2, figsize=(11, 5))\n","\n","    for classifiers in classifier_list:\n","        classifier = joblib.load(f'../model/sample_1_{sample_size}/{classifiers}')\n","        y_pred = classifier.predict(X_test)\n","        RocCurveDisplay.from_predictions(y_test, y_pred, ax=ax_roc, name=classifier.__class__.__name__)\n","        PrecisionRecallDisplay.from_predictions(y_test, y_pred, ax=ax_prc, name=classifier.__class__.__name__)\n","\n","    ax_roc.set_title(f\"ROC-AUC Curve (1:{sample_size}) Ratio\")\n","    ax_prc.set_title(f\"Precision Recall Curve (1:{sample_size}) Ratio\")\n","\n","    ax_roc.grid(linestyle=\"--\")\n","    ax_prc.grid(linestyle=\"--\")\n","\n","    return"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-26T21:23:47.296775Z","iopub.status.busy":"2023-10-26T21:23:47.296344Z","iopub.status.idle":"2023-10-26T21:25:40.603851Z","shell.execute_reply":"2023-10-26T21:25:40.602209Z","shell.execute_reply.started":"2023-10-26T21:23:47.296733Z"},"trusted":true},"outputs":[],"source":["%%time\n","# Train Model with Different Sample Size\n","\n","performance_dataset = pd.DataFrame()\n","\n","sample_size = 1\n","\n","X_train, y_train, X_test, y_test = create_sample_set(intellifraud_dataset_num, sample_size)\n","print('In Sample Size {}, Traing Set - {} and Test Set - {}'.format(sample_size, X_train.shape[0], X_test.shape[0]))\n","\n","# Machine Learning Model Build\n","classifier_model = [\n","                    AdaBoostClassifier(learning_rate = 0.1, n_estimators=500, random_state=42), \n","                    XGBClassifier(colsample_bytree=1.0, gamma=5, learning_rate=1.0, max_depth=5, min_child_weight=1,    n_estimators=10, subsample=1.0, random_state=42),\n","                    LGBMClassifier(boosting_type = 'dart', colsample_bytree=1.0, learning_rate = 0.1, max_depth=10,n_estimators = 50, subsample=0.6, random_state=42, verbose=-1)\n","                ]\n","\n","# Call Classification module\n","ind_class_model_df        = build_individual_classifier_model(X_train, X_test, y_train, y_test, classifier_model, sample_size)\n","ind_voting_model_df       = build_voting_classifier_model(X_train, X_test, y_train, y_test, classifier_model, ind_class_model_df, sample_size)\n","ind_voting_stack_model_df = build_stacking_classifier_model(X_train, X_test, y_train, y_test, classifier_model, ind_voting_model_df, sample_size)\n","ind_voting_stack_model_df['Sample_Size'] = f'1:{sample_size}'\n","ind_voting_stack_model_df.to_csv(f'performance_for_1_{sample_size}.csv', index=False)\n","performance_dataset = performance_dataset.append(ind_voting_stack_model_df)\n","    \n","# Show Performance Viz\n","create_performance_graphs(X_test, y_test, sample_size)\n","    "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%%time\n","# Train Model with Different Sample Size\n","\n","# performance_dataset = pd.DataFrame()\n","\n","sample_size = 2\n","\n","X_train, y_train, X_test, y_test = create_sample_set(intellifraud_dataset_num, sample_size)\n","print('In Sample Size {}, Traing Set - {} and Test Set - {}'.format(sample_size, X_train.shape[0], X_test.shape[0]))\n","\n","# Machine Learning Model Build\n","classifier_model = [\n","                    AdaBoostClassifier(learning_rate = 0.1, n_estimators=500, random_state=42), \n","                    XGBClassifier(colsample_bytree=1.0, gamma=5, learning_rate=1.0, max_depth=5, min_child_weight=1,    n_estimators=10, subsample=1.0, random_state=42),\n","                    LGBMClassifier(boosting_type = 'dart', colsample_bytree=1.0, learning_rate = 0.1, max_depth=10,n_estimators = 50, subsample=0.6, random_state=42, verbose=-1)\n","                ]\n","\n","# Call Classification module\n","ind_class_model_df        = build_individual_classifier_model(X_train, X_test, y_train, y_test, classifier_model, sample_size)\n","ind_voting_model_df       = build_voting_classifier_model(X_train, X_test, y_train, y_test, classifier_model, ind_class_model_df, sample_size)\n","ind_voting_stack_model_df = build_stacking_classifier_model(X_train, X_test, y_train, y_test, classifier_model, ind_voting_model_df, sample_size)\n","ind_voting_stack_model_df['Sample_Size'] = f'1:{sample_size}'\n","ind_voting_stack_model_df.to_csv(f'performance_for_1_{sample_size}.csv', index=False)\n","performance_dataset = performance_dataset.append(ind_voting_stack_model_df)\n","    \n","# Show Performance Viz\n","create_performance_graphs(X_test, y_test, sample_size)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%%time\n","# Train Model with Different Sample Size\n","\n","# performance_dataset = pd.DataFrame()\n","sample_size = 3\n","\n","X_train, y_train, X_test, y_test = create_sample_set(intellifraud_dataset_num, sample_size)\n","print('In Sample Size {}, Traing Set - {} and Test Set - {}'.format(sample_size, X_train.shape[0], X_test.shape[0]))\n","\n","# Machine Learning Model Build\n","classifier_model = [\n","                    AdaBoostClassifier(learning_rate = 0.1, n_estimators=500, random_state=42), \n","                    XGBClassifier(colsample_bytree=1.0, gamma=5, learning_rate=1.0, max_depth=5, min_child_weight=1,    n_estimators=10, subsample=1.0, random_state=42),\n","                    LGBMClassifier(boosting_type = 'dart', colsample_bytree=1.0, learning_rate = 0.1, max_depth=10,n_estimators = 50, subsample=0.6, random_state=42, verbose=-1)\n","                ]\n","\n","# Call Classification module\n","ind_class_model_df        = build_individual_classifier_model(X_train, X_test, y_train, y_test, classifier_model, sample_size)\n","ind_voting_model_df       = build_voting_classifier_model(X_train, X_test, y_train, y_test, classifier_model, ind_class_model_df, sample_size)\n","ind_voting_stack_model_df = build_stacking_classifier_model(X_train, X_test, y_train, y_test, classifier_model, ind_voting_model_df, sample_size)\n","ind_voting_stack_model_df['Sample_Size'] = f'1:{sample_size}'\n","ind_voting_stack_model_df.to_csv(f'performance_for_1_{sample_size}.csv', index=False)\n","performance_dataset = performance_dataset.append(ind_voting_stack_model_df)\n","    \n","# Show Performance Viz\n","create_performance_graphs(X_test, y_test, sample_size)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["performance_dataset"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%%time\n","# Train Model with Different Sample Size\n","\n","performance_dataset1 = pd.DataFrame()\n","\n","for sample_size in range(1, 2):\n","\n","    X_train, y_train, X_test, y_test = create_sample_set(intellifraud_dataset_num, sample_size)\n","    print('In Sample Size {}, Traing Set - {} and Test Set - {}'.format(sample_size, X_train.shape[0], X_test.shape[0]))\n","\n","    # Machine Learning Model Build\n","    classifier_model = [\n","                        AdaBoostClassifier(learning_rate = 0.1, n_estimators=500, random_state=42), \n","                        XGBClassifier(colsample_bytree=1.0, gamma=5, learning_rate=1.0, max_depth=5, min_child_weight=1,    n_estimators=10, subsample=1.0, random_state=42),\n","                        LGBMClassifier(boosting_type = 'dart', colsample_bytree=1.0, learning_rate = 0.1, max_depth=10,n_estimators = 50, subsample=0.6, random_state=42, verbose=-1)\n","                    ]\n","\n","    # Call Classification module\n","    ind_class_model_df        = build_individual_classifier_model(X_train, X_test, y_train, y_test, classifier_model, sample_size)\n","    ind_voting_model_df       = build_voting_classifier_model(X_train, X_test, y_train, y_test, classifier_model, ind_class_model_df, sample_size)\n","    ind_voting_stack_model_df = build_stacking_classifier_model(X_train, X_test, y_train, y_test, classifier_model, ind_voting_model_df, sample_size)\n","    ind_voting_stack_model_df['Sample_Size'] = f'1:{sample_size}'\n","\n","    performance_dataset = performance_dataset.append(ind_voting_stack_model_df)\n","    \n","    # Show Performance Viz\n","    create_performance_graphs(X_test, y_test, sample_size)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["performance_dataset.to_csv('../model/performance.csv', index=False)"]},{"cell_type":"markdown","metadata":{},"source":["### GRID SEARCH"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%%time\n","# Light GBM base model\n","# Initiate classifier to use\n","lgbm_classifier = LGBMClassifier(random_state=42)\n","\n","# Grid Search for Light GBM\n","gridParams = {\n","                'n_estimators': [10, 50, 100, 500],\n","                'learning_rate': [0.0001, 0.001, 0.01, 0.1, 1.0],\n","                'boosting_type' : ['gbdt', 'dart'], # for better accuracy -> try dart\n","                'colsample_bytree': [0.6, 0.8, 1.0],\n","                'subsample' : [0.6, 0.8, 1.0],\n","                'max_depth': [2, 4, 6, 8, 10]\n","    }\n","\n","grid = GridSearchCV(lgbm_classifier, gridParams, verbose=1, cv=4, n_jobs=-1, scoring = 'recall')\n","# Run the grid\n","grid.fit(X_train, y_train)\n","\n","# Print the best parameters found\n","print(grid.best_params_)\n","print(grid.best_score_)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%%time\n","# Xtreme GBM base model\n","# Initiate classifier to use\n","xgb_classifier = XGBClassifier(random_state=42)\n","\n","# Grid Search for XGBOOST\n","gridParams = {\n","        'n_estimators': [10, 50, 100, 500],\n","        'learning_rate': [0.0001, 0.001, 0.01, 0.1, 1.0],\n","        'min_child_weight': [1, 5, 10],\n","        'gamma': [0.5, 1, 1.5, 2, 5],\n","        'subsample': [0.6, 0.8, 1.0],\n","        'colsample_bytree': [0.6, 0.8, 1.0],\n","        'max_depth': [3, 4, 5]\n","        }\n","\n","grid = GridSearchCV(xgb_classifier, gridParams, verbose=1, cv=5, n_jobs=-1, scoring = 'recall')\n","# Run the grid\n","grid.fit(X_train, y_train)\n","\n","# Print the best parameters found\n","print(grid.best_params_)\n","print(grid.best_score_)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%%time\n","# AdaBoost Base Model\n","# Initiate classifier to use\n","abc_classifier = AdaBoostClassifier(random_state=42)\n","\n","# Grid Search for XGBOOST\n","gridParams = {\n","        'n_estimators': [10, 50, 100, 500],\n","        'learning_rate': [0.0001, 0.001, 0.01, 0.1, 1.0],\n","        }\n","\n","grid = GridSearchCV(abc_classifier, gridParams, verbose=1, cv=5, n_jobs=-1, scoring = 'recall')\n","# Run the grid\n","grid.fit(X_train, y_train)\n","\n","# Print the best parameters found\n","print(grid.best_params_)\n","print(grid.best_score_)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, PrecisionRecallDisplay, RocCurveDisplay"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["for sample_size in range(1, 2):\n","\n","    X_train, y_train, X_test, y_test = create_sample_set(intellifraud_dataset_num, sample_size)\n","    print('In Sample Size {}, Traing Set - {} and Test Set - {}'.format(sample_size, X_train.shape[0], X_test.shape[0]))\n","\n","    classifier = joblib.load('../model/sample_1_1/VotingClassifier.pkl')\n","    predictions = classifier.predict(X_test)\n","    cm = confusion_matrix(y_test, predictions, labels=classifier.classes_)\n","    disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n","                                display_labels=['No Fraud', 'Fraud'])\n","    disp.plot()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.metrics import DetCurveDisplay, RocCurveDisplay\n","\n","# Sample Ratio 1:1\n","classifier_list = ['AdaBoostClassifier.pkl', 'LGBMClassifier.pkl', 'XGBClassifier.pkl', 'StackingClassifier.pkl', 'VotingClassifier.pkl']\n","\n","fig, [ax_roc, ax_prc] = plt.subplots(1, 2, figsize=(11, 5))\n","\n","# Required to extract the test data\n","X_train, y_train, X_test, y_test = create_sample_set(intellifraud_dataset_num, 1) # 1is for 1:1 Sample.\n","\n","for classifiers in classifier_list:\n","    classifier = joblib.load(f'../model/sample_1_1/{classifiers}')\n","    RocCurveDisplay.from_estimator(classifier, X_test, y_test, ax=ax_roc, name=classifier.__class__.__name__)\n","    PrecisionRecallDisplay.from_estimator(classifier, X_test, y_test, ax=ax_prc, name=classifier.__class__.__name__)\n","\n","ax_roc.set_title(\"ROC-AUC Curve (1:1) Ratio\")\n","ax_prc.set_title(\"Precision Recall Curve (1:1) Ratio\")\n","\n","ax_roc.grid(linestyle=\"--\")\n","ax_prc.grid(linestyle=\"--\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Sample Ratio 1:2\n","classifier_list = ['AdaBoostClassifier.pkl', 'LGBMClassifier.pkl', 'XGBClassifier.pkl', 'StackingClassifier.pkl', 'VotingClassifier.pkl']\n","\n","fig, [ax_roc, ax_prc] = plt.subplots(1, 2, figsize=(11, 5))\n","\n","# Required to extract the test data\n","X_train, y_train, X_test, y_test = create_sample_set(intellifraud_dataset_num, 2) # 2 is for 1:2 Sample.\n","\n","for classifiers in classifier_list:\n","    classifier = joblib.load(f'../model/sample_1_2/{classifiers}')\n","    RocCurveDisplay.from_estimator(classifier, X_test, y_test, ax=ax_roc, name=classifier.__class__.__name__)\n","    PrecisionRecallDisplay.from_estimator(classifier, X_test, y_test, ax=ax_prc, name=classifier.__class__.__name__)\n","\n","ax_roc.set_title(\"ROC-AUC Curve (1:2) Ratio\")\n","ax_prc.set_title(\"Precision Recall Curve (1:2) Ratio\")\n","\n","ax_roc.grid(linestyle=\"--\")\n","ax_prc.grid(linestyle=\"--\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Sample Ratio 1:3\n","classifier_list = ['AdaBoostClassifier.pkl', 'LGBMClassifier.pkl', 'XGBClassifier.pkl', 'StackingClassifier.pkl', 'VotingClassifier.pkl']\n","\n","fig, [ax_roc, ax_prc] = plt.subplots(1, 2, figsize=(11, 5))\n","\n","# Required to extract the test data\n","X_train, y_train, X_test, y_test = create_sample_set(intellifraud_dataset_num, 3) # 3 is for 1:3 Sample.\n","\n","for classifiers in classifier_list:\n","    classifier = joblib.load(f'../model/sample_1_3/{classifiers}')\n","    RocCurveDisplay.from_estimator(classifier, X_test, y_test, ax=ax_roc, name=classifier.__class__.__name__)\n","    PrecisionRecallDisplay.from_estimator(classifier, X_test, y_test, ax=ax_prc, name=classifier.__class__.__name__)\n","\n","ax_roc.set_title(\"ROC-AUC Curve (1:3) Ratio\")\n","ax_prc.set_title(\"Precision Recall Curve (1:3) Ratio\")\n","\n","ax_roc.grid(linestyle=\"--\")\n","ax_prc.grid(linestyle=\"--\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"}},"nbformat":4,"nbformat_minor":4}
